from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from app.api import chat
import os
import logging
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('llm-classroom.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)

app = FastAPI(
    title="LLM Classroom Proto3",
    description="RTCF í”„ë¡¬í”„íŠ¸ í•™ìŠµ í”Œë«í¼ - ë‹¨ì¼ ì„œë²„ êµ¬ì¡°",
    version="3.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API ë¼ìš°í„° ì¶”ê°€
app.include_router(chat.router, prefix="/api", tags=["chat"])

@app.get("/api")
async def api_root():
    return {"message": "Welcome to LLM Classroom Proto3 API"}

@app.get("/")
async def root():
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/index.html")

# Static files for frontend (ì´ê²ƒì€ ë§ˆì§€ë§‰ì— ì™€ì•¼ í•¨)
app.mount("/", StaticFiles(directory="frontend", html=True), name="static")


if __name__ == "__main__":
    import uvicorn
    import os
    
    # OpenAI API í‚¤ ê²€ì¦
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        logger.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("âŒ ì˜¤ë¥˜: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ì„¸ìš”:")
        print("export OPENAI_API_KEY=your_api_key_here")
        exit(1)
    elif len(openai_api_key) < 40:
        logger.warning("âš ï¸ OPENAI_API_KEYê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ í‚¤ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    else:
        logger.info("âœ… OPENAI_API_KEY í™•ì¸ë¨")
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 8002))
    reload = os.getenv("ENV", "development") != "production"
    
    logger.info(f"ğŸš€ Starting LLM Classroom Proto3 server...")
    logger.info(f"ğŸ“ Host: {host}")
    logger.info(f"ğŸŒ Port: {port}")
    logger.info(f"ğŸ”„ Reload: {reload}")
    logger.info(f"ğŸŒ Environment: {os.getenv('ENV', 'development')}")
    
    print(f"ğŸš€ Starting LLM Classroom Proto3 server...")
    print(f"ğŸ“ Host: {host}")
    print(f"ğŸŒ Port: {port}")
    print(f"ğŸ”„ Reload: {reload}")
    print(f"ğŸŒ Environment: {os.getenv('ENV', 'development')}")
    print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: llm-classroom.log")
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=reload,
        log_level="info"
    )